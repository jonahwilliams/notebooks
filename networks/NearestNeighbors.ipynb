{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cPickle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Image Classification</h3>\n",
    "Below we load the CIFAR-10 Dataset into python.  Availible at http://www.cs.toronto.edu/~kriz/cifar.html.  This is just some of the basics from http://cs231n.github.io/classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = ['cifar-10-batches-py/data_batch_' + str(i) for i in range(1, 6)]\n",
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "batches = map(unpickle, files)\n",
    "X = np.concatenate([b['data'] for b in batches])\n",
    "y = np.concatenate([b['labels'] for b in batches])\n",
    "\n",
    "X_test = map(unpickle, ['cifar-10-batches-py/test_batch'])[0]['data']\n",
    "y_test = map(unpickle, ['cifar-10-batches-py/test_batch'])[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[158, 159, 165, ..., 124, 129, 110],\n",
       "       [235, 231, 232, ..., 178, 191, 199],\n",
       "       [158, 158, 139, ...,   8,   3,   7],\n",
       "       ..., \n",
       "       [ 20,  19,  15, ...,  50,  53,  47],\n",
       "       [ 25,  15,  23, ...,  80,  81,  80],\n",
       "       [ 73,  98,  99, ...,  94,  58,  26]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 32x32 images are encoded as flattened numpy arrays;  The first 1024 digits encode the red values, then blue and green, respectively\n",
    "\n",
    "<h3>Nearest Neighbors Classifier</h3>\n",
    "The simpliest classified for data is to simply predict the class value $y^*$ for a novel input $x^*$ as the label $y$ of the closest input $x$.  How we defined \"closeness\" is important; two common choices for this distance metric are the Euclidian Distance (L2) and the Manhatten Distance (L1).\n",
    "\n",
    "\n",
    "A simple Algorithm to classify a new image would work as follows:\n",
    "\n",
    "1.  Recieve input $x^*$\n",
    "2.  For each training data $(x, y)$\n",
    "    2a. Calculate distance $d(x, x^*)$, storing target class $y$ of closest training input\n",
    "3. Predict class $y$\n",
    "\n",
    "\n",
    "Below I take advantage of numpy arrays to perform a slightly faster computation - Though you'll note it is still very slow.  Because our model is the data itself, it scales poorly with data size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def l2(a, b):\n",
    "    \"\"\"Calculates L2 distance between two vectors\"\"\"\n",
    "    return np.sum((a - b)**2, axis=1)\n",
    "def l1(a, b):\n",
    "    \"\"\"Calculates L1 distance between two vectors\"\"\"\n",
    "    return np.sum(np.abs(a - b), axis=1)\n",
    "\n",
    "# Create numpy array of zeroes to store predictions\n",
    "y_pred = np.zeros_like(y_test)\n",
    "\n",
    "for i, test_image in enumerate(X_test[:200]):\n",
    "    y_pred[i] = y[np.argmin(l2(test_image, X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.695\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "for a, b in zip(y_pred[:200], y_test[:200]):\n",
    "    if (a != b):\n",
    "        errors +=1\n",
    "print \"Test Accuracy: \" + str(errors / 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>K-Nearest Neighbors Classifier</h3>\n",
    "To improve the performance of the above algorithm, we can take the average (regression) or consesus (classification) of the $k$ nearest datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "for i, test_image in enumerate(X_test[:200]):\n",
    "    y_pred[i] = np.argmax(np.bincount(y[np.argsort(l2(test_image, X))][:k]))\n",
    "    \n",
    "errors = 0\n",
    "for a, b in zip(y_pred[:200], y_test[:200]):\n",
    "    if (a != b):\n",
    "        errors +=1\n",
    "print \"Test Accuracy: \" + str(errors / 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Improving Performance with K-Means</h3>\n",
    "Ultimatly we need to improve the performance of the above algorithms if we want to use them at any larger scale.  One method to do so is by preprocessing the data with the K-means algorithm - then running the k-nearest neighbors on the dataset of means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "KM = KMeans(n_clusters=100)\n",
    "X_mod = KM.fit_predict(X)\n",
    "\n",
    "k = 10\n",
    "for i, test_image in enumerate(X_test):\n",
    "    y_pred[i] = np.argmax(np.bincount(y[np.argsort(l2(test_image, X_mod))][:k]))\n",
    "    \n",
    "errors = 0\n",
    "for a, b in zip(y_pred[:200], y_test[:200]):\n",
    "    if (a != b):\n",
    "        errors +=1\n",
    "print \"Test Accuracy: \" + str(errors / 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
