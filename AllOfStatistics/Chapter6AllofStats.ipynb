{
 "metadata": {
  "name": "",
  "signature": "sha256:2f245cd6154a18aefab737338792f6e21d9496ffc8ec26c1a475225cb72028d8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Chapter 6 - Models, Statistical Inference, and Learning</h1>\n",
      "\n",
      "Statistical inference (statistics) or learning (computer science) is the process of using data to make inferences about the distribution that generated the data.  For example, given $X_1, X_2, ..., X_n$ what is $F$?\n",
      "\n",
      "A statistical model $F$ is a set of distributions (or densities or regression functions).  A parametric model is a set $F$ that can be parameterized by a finite number of parameters.  For example, if we assume that some data comes from a normal distribution, then it is modeled as $N(\\mu, \\sigma)$ with two parameters.\n",
      "\n",
      "In general, a parametric model takes the form\n",
      "\n",
      "$F = \\{f(x, \\theta) : \\theta \\in \\Theta\\}$\n",
      "\n",
      "Where $\\theta$ is an unknown vector of parameters that takes on values in the parameter space $\\Theta$.  A nonparametric model $F$ is one that cannot be parameterized by a finite number of parameters.\n",
      "\n",
      "<h2>Example 1 (One Dimensional Parametric Estimation)</h2>\n",
      "\n",
      "Let $X_1, X_2, ..., X_n$ be independent Bernouli observations, then estimate the parameter $p$.\n",
      "Given that the p.d.f. of a Bernouli distribution is\n",
      "\n",
      "$f(x, \\theta) = p(1 - p)$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "np.mean([0, 1, 1, 0, 1, 0, 1, 0, 0, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "0.5"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Example 2 (Two Dimensional Parametric Estimation)</h2>\n",
      "\n",
      "Let $X_1, X_2, ..., X_n$ be independent normal observations, then estimate the parameters $\\mu$ and $\\sigma$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats as sp\n",
      "data = sp.norm(2, 3).rvs(size=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "array([  2.77802289,   2.25754462,   2.28462004,   2.97204727,\n",
        "         1.33901807,   3.89325252,  -1.18336498,   2.21366649,\n",
        "         4.594918  ,  -6.40142052,   1.7619329 ,   2.9773209 ,\n",
        "        -1.71491735,   6.2727497 ,  -0.20415204,  -0.5503575 ,\n",
        "         1.00313947,  -0.99065911,   7.00839204,   7.46718213,\n",
        "         0.07979801,  -0.51990291,   4.14451017,  -0.84443676,\n",
        "         1.03380777,   4.51091466,   8.54652769,   1.86996226,\n",
        "         2.72358374,  10.45732917,   3.64849334,  -1.64605373,\n",
        "         5.26340629,  -3.23709163,   2.15919242,   4.70990707,\n",
        "        -2.36519869,   1.49751081,   7.39659395,   4.29023896,\n",
        "         2.47236648,   1.85675977,  -1.00695072,  -0.67084989,\n",
        "         2.91345082,  -1.32686589,   2.65118652,  -2.41708225,\n",
        "         8.26823764,  -5.15275586,   0.6864399 ,   0.86820946,\n",
        "         1.24795614,   3.09671129,   4.37092694,  -1.69750851,\n",
        "         5.7594049 ,   2.43589283,  -1.45693474,  -0.8152073 ,\n",
        "        -0.3025212 ,   2.7197746 ,  10.09600519,   3.95741467,\n",
        "         6.94236278,   0.35872286,   2.54552357,   4.6508267 ,\n",
        "        -3.9641735 ,   1.81405434,   5.64088084,  -1.59267986,\n",
        "         5.34318817,   8.84691138,  -1.82331915,   1.93356427,\n",
        "         2.49133907,   5.43523467,  -0.70613869,   3.12560314,\n",
        "         0.48134359,   1.13116487,   4.89292712,   5.58176625,\n",
        "         4.76264692,   2.57213278,   1.69370836,  -1.72912292,\n",
        "         3.12294087,   5.1890933 ,   3.00846644,  -0.56133539,\n",
        "         1.60765035,   0.09715134,   1.45530415,   2.63316413,\n",
        "        -0.56483294,   3.60101961,   5.56716569,   1.91711763])"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean = np.mean(data)\n",
      "std = np.std(data)\n",
      "mean, std"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(2.1755346170981507, 3.1824061963783925)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Other Examples:</h2>\n",
      "\n",
      "Suppose we have observed pairs of data $(X_1, Y_1), ..., (X_n, Y_n)$ and we seek to predict $Y_{new} $  from $X_{new}$.  The problem is refered to as a regression problem if Y is continuous and a classification problem if Y is discrete.  If we assume the function $F$ has finite parameters, such as the set of all straight lines, then it is a parametric regression.  Alternatively, if we assume that $F$ is not finite dimensional, then we have a non parametric regression.  Regression models are frequently written as\n",
      "\n",
      "$Y = r(X) + \\epsilon$\n",
      "\n",
      "Where $\\epsilon$ ~ $N(0, 1)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Fundamental Concepts in Inference</h1>\n",
      "\n",
      "<h2>Point Estimation</h2>\n",
      "point estimation refers to finding a bestguess for some parameter of $F$, probability density function, or regression equation.  We generally refer to an estimate of $\\theta$ as $\\hat{\\theta}$.  Suppose $X_1, X_2, ..., X_n$ are drawn iid from some distribution $F$.  Then a point estimator $\\hat{\\theta}$ of the data is a function,\n",
      "\n",
      "$\\hat{\\theta} = g(X_1, X_2, ..., X_n)$\n",
      "\n",
      "Where $\\theta$ is some fixed and unknown quantity, its estimator is a random variable.\n",
      "\n",
      "<h3>Bias</h3>\n",
      "The bias of an estimator is defined as\n",
      "\n",
      "$\\hat{\\theta} = \\theta + Bias$\n",
      "\n",
      "An estimator is unbiased if $E(\\hat{\\theta}) = \\theta$. The bias of an estimator isn't as important as consistency.\n",
      "\n",
      "<h3>Consistency</h3>\n",
      "\n",
      "A point estimator $\\hat{\\theta}$ is consistent if $\\hat{\\theta} \\rightarrow \\theta$ as $n \\rightarrow \\infty$\n",
      "The quality of a point estimate is sometimes assed by its mean squared error, or MSE, defined as\n",
      "\n",
      "$MSE = E_{\\theta}(\\hat{\\theta}_n - \\theta)^2$\n",
      "\n",
      "The MSE can be written as\n",
      "\n",
      "$MSE = bias^2(\\hat{\\theta_n}) + V_{\\theta}(\\hat{\\theta_n})$\n",
      "\n",
      "An estimator is asymptotically normal if\n",
      "\n",
      "$\\frac{\\hat{\\theta}_n - \\theta}{se} \\rightarrow N(0, 1)$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}