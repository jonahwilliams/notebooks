{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Discrete State Markov Models</h2>\n",
    "the timeseries models we consider are probability models over a collection fo random variables $v_1, v_2, ..., v_T$ with individual values $v_T$ indexed by discrete time $T$.  A probabilistic time series model requires a specification of the joint distribution $p(v_1, v_2, ..., v_T)$.  for the case in which the observed data are discrete, the joint probability table has exponentially many entries.  we therefore cannot expect to idependently specify all the entries needed and must make simpler models under which these entries can be paramterized in a lower dimensional manner.  Such simplifications are the heart of time series modeling.\n",
    "\n",
    "\n",
    "<h4>Definition 23.1  Timeseries Notation</h4>\n",
    "$X_{a:b} \\equiv x_a, x_{a+1}, ..., x_b$, with $x_{a:b} = x_a$ for $b \\leq a$\n",
    "\n",
    "For timeseries data $v_1, v_2, ..., v_T$ we need a model $p(v{1:T})$.  For consistency with the causal nature of time, it is natural to consider the cascade decomposition.\n",
    "\n",
    "\n",
    "$$P(v_{1:T}) = \\prod \\limits_{t=1}^T p(v_t | v_{1:t-1})$$\n",
    "\n",
    "With the convention that $p(v_t|v_{1:t-1}) = p(v_1)$ for $t=1$.  It is often useful to assume that the immediate past is more relevant than the remote past and in markov models only a limited number of previous observations are required to predict the future.\n",
    "\n",
    "<h4>Definition 23.2 Markov Chain</h4>\n",
    "A Markov chain defined on either discrete or continuous variables $v_{1:T}$ is one in which the following conditional independence assumption holds:\n",
    "\n",
    "$$p(v_t|v_1, ..., v_{t-1}) = p(v_t|v_{t - L}, ..., v_{t-1})$$\n",
    "\n",
    "Where $L \\geq 1$ is the order of the markov chain.  For a stationary markov chain, the transitions are time independent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Equilibrium and Stationary Distribution of a Markov Chain</h3>\n",
    "for a given transition $p(x_t|x_{t-1})$, it is interesting to know how the marginal $p(x_t)$ evolves through time.  For a discrete state system, this is given by\n",
    "\n",
    "$$p(x_t = i) = \\sum \\limits_{j} p(x_t = i | x_{t-1} = j) p(x_{t-1} = j) $$\n",
    "\n",
    "For an initial distribution $p(x_1)$, the bove recursively defines the marginal for all future timepoints.  The marginal $p(x_t = i)$ has the interpretation of the frequency that we visit state $i$ at time $t$, given we started with a sample from $p(x_1)$ and subsequently repeatedly drew samples from the transition $p(x_{\\tau}|x_{\\tau - 1})$\n",
    "\n",
    "$$p_t = Mp_{t-1} = M^{t-1}p_1$$\n",
    "\n",
    "If, for $t \\rightarrow \\infty, p_{\\infty}$ is independent of the inital distribution $p_1$, then $p_{\\infty}$ is called the quilibrium distribution of the chain.  In matrix notation this can be written as the vector equation\n",
    "\n",
    "\n",
    "$$p_{\\infty} = M p_{\\infty}$$\n",
    "\n",
    "So that the stationary distribution is proportional to the eigen vector with unit eigenvalue of the transition matrix.  There may be more than one stationary distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fitting Markov Models</h3>\n",
    "\n",
    "Given a sequence $v_{1:T}$, fitting a stationary first-order markov chain by maximum likelihood corresponds to setting the transitions by counting the number of observed (first-order) transitions in the sequence:\n",
    "\n",
    "$$p(v_t = i \\  | v_{t-1} = j) \\propto\\sum \\limits_{t=2}^T I[v_t = i, v_{t-1} = j]$$\n",
    "\n",
    "To show this, we write $p(v_t = i | v_{t-1} = j) \\equiv \\theta_{i|j}$, so that the likelihood (assuming $v_1$ is known):\n",
    "\n",
    "$$p(v_{2:T}| \\theta, v_1) = \\prod \\limits_{t=2}^T \\theta_{v_t|v_t-1} = \\prod \\limits_{t=2}^T \\prod \\limits_{i,j} \\theta_{i|j}^{I[v_t = i, v_{t-1} = j]}$$\n",
    "\n",
    "Taking logs and adding the Lagrange constraint for normalization,\n",
    "\n",
    "$$L(\\theta) = \\sum \\limits_{t=2}^T \\sum \\limits_{i,j} I[v_t = i, v_{t-1} = j] log \\theta_{i|j} + \\sum \\limits_{j} \\lambda_j (1 - \\sum_i \\theta_{i|j})$$\n",
    "\n",
    "Thus, the unsurprising result is that the transition probability matrix is established by counting all the transitions and normalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
