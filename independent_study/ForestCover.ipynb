{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 2596</td>\n",
       "      <td>  51</td>\n",
       "      <td>  3</td>\n",
       "      <td> 258</td>\n",
       "      <td>   0</td>\n",
       "      <td>  510</td>\n",
       "      <td> 221</td>\n",
       "      <td> 232</td>\n",
       "      <td> 148</td>\n",
       "      <td> 6279</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2590</td>\n",
       "      <td>  56</td>\n",
       "      <td>  2</td>\n",
       "      <td> 212</td>\n",
       "      <td>  -6</td>\n",
       "      <td>  390</td>\n",
       "      <td> 220</td>\n",
       "      <td> 235</td>\n",
       "      <td> 151</td>\n",
       "      <td> 6225</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2804</td>\n",
       "      <td> 139</td>\n",
       "      <td>  9</td>\n",
       "      <td> 268</td>\n",
       "      <td>  65</td>\n",
       "      <td> 3180</td>\n",
       "      <td> 234</td>\n",
       "      <td> 238</td>\n",
       "      <td> 135</td>\n",
       "      <td> 6121</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2785</td>\n",
       "      <td> 155</td>\n",
       "      <td> 18</td>\n",
       "      <td> 242</td>\n",
       "      <td> 118</td>\n",
       "      <td> 3090</td>\n",
       "      <td> 238</td>\n",
       "      <td> 238</td>\n",
       "      <td> 122</td>\n",
       "      <td> 6211</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2595</td>\n",
       "      <td>  45</td>\n",
       "      <td>  2</td>\n",
       "      <td> 153</td>\n",
       "      <td>  -1</td>\n",
       "      <td>  391</td>\n",
       "      <td> 220</td>\n",
       "      <td> 234</td>\n",
       "      <td> 150</td>\n",
       "      <td> 6172</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points     ...      Soil_Type32  Soil_Type33  \\\n",
       "0                                6279     ...                0            0   \n",
       "1                                6225     ...                0            0   \n",
       "2                                6121     ...                0            0   \n",
       "3                                6211     ...                0            0   \n",
       "4                                6172     ...                0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           5  \n",
       "1            0            0           5  \n",
       "2            0            0           2  \n",
       "3            0            0           2  \n",
       "4            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/jonahwilliams/Documents/Kaggle/Forest/train.csv\")\n",
    "data = data.drop(\"Id\", axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So here we have the forrest cover data - it looks like we have several real-valued dimensions, as well as several binary dimensions.  With a mix of data types, a good first stab is a random forrest.  \n",
    "\n",
    "I'll go ahead and create a validation set for comparison of the different model techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.values[:, 0:-1]\n",
    "y = data.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2596,   51,    3, ...,    0,    0,    0],\n",
       "       [2590,   56,    2, ...,    0,    0,    0],\n",
       "       [2804,  139,    9, ...,    0,    0,    0],\n",
       "       ..., \n",
       "       [2492,  134,   25, ...,    0,    0,    0],\n",
       "       [2487,  167,   28, ...,    0,    0,    0],\n",
       "       [2475,  197,   34, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 2, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(verbose=True)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85449735449735453"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAjYAAAJACAYAAACezSzpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu4JVV55/Fvnaa7QW2IRm1pYpRM5I0xggIKInIJASFe\n",
       "MCQZnYAoXpCIBmdiMKJDYsZEJgYUHtRkQGg0GEcIIsoIJEFBmAQkXvCWFxCZGRVQEWkbufTlzB9V\n",
       "R46kzzm7u09V7V3r++mnHnbts7vW2iL0y2+9taqanp5GkiRpCKb6noAkSdJisbCRJEmDYWEjSZIG\n",
       "w8JGkiQNxjZ9T0CSJLUrIrYBfqGHob+dmeu7HNDCRpKk4fsF4Fs9jLszcFuXA1rYSJJUiDuX78n6\n",
       "atvWx9lm+n5WPnBD6+NscuxeRpUkSZ1bX23Lhqnt2h9oY/tDzMXCRpKkUlRT9dHFOD3xrihJkjQY\n",
       "JjaSJJWiAqqqm3F6YmIjSZIGw8RGkqRS2GMjSZI0OSxsJEnSYLgUJUlSKaqqo+bh/rqHTWwkSdJg\n",
       "mNhIklQKm4clSZImh4mNJEnF6KjHpscd+kxsJEnSYJjYSJJUiqrqqMfGxEaSJGmrmdhIklQK97GR\n",
       "JEmaHCY2kiSVwn1sJEmSJoeFjSRJGgyXoiRJKoXNw5IkSZPDxEaSpFLYPCxJkjQ5TGwkSSqFPTaS\n",
       "JEmTw8RGkqRS+BBMSZKkyWFiI0lSMTq6K2qB3CQilgLnAE8ClgPvBL4BrAY2Al8Fjs/M6Yh4LXAs\n",
       "sB54Z2ZeuuUjS5IkLb4jge9n5n7AocD7gFOBk5r3KuDwiHgC8EZgH+D5wLsiYtl8FzaxkSSpFFNV\n",
       "fXQxzvwuAC6c+TSwDtg9M69u3vs0cAiwAbg2M9cB6yLiFmBX4Ia5LmxhI0mSOpWZ9wJExArqIuft\n",
       "wF/N+siPgR2A7YF7NvH+nFyKkiRJnYuIJwJXAh/KzL+j7q2ZsT3wI2ANsGLW+yuAu+e7roWNJEml\n",
       "mHmkQhfHPCJiJXAFcGJmrm7e/mJE7N+8Pgy4GrgeeF5ELI+IHYCnUjcWz8mlKEmS1LWTqJeUTo6I\n",
       "k5v3TgDOaJqDvw5c2NwVdQbwOeow5qTMfHC+C1fT09MtzluSJPUtIp4MfOs7T/htNmzzqNbHW7J+\n",
       "LTvd8fcAO2fmba0POItLUZIkaTBcipIkqRQ+UkGSJGlymNhIklSKquomTTGxkSRJ2nomNpIklWKE\n",
       "PWYWbZyemNhIkqTBsLCRJEmD4VKUJEnF6Kh5GJuHJUmStpqJjSRJpbB5WJIkaXKY2EiSVIqKjjbo\n",
       "a3+IuZjYSJKkwTCxkSSpFPbYSJIkTY6xSGwiYjnwLOB2YEPP05EkqQtLgB2Bz2fmA52MWMBDMMei\n",
       "sKEuaj7X9yQkSerB84Br+p7EUIxLYXM7wF27HM3GZdv3PZdefOLth/U9hV6tesy2fU9BPVq3frrv\n",
       "KfRq6TY93kIyBu5/sMyg/nt33sFxrz4amj8DO1FAj824FDYbADYu254Ny3+u77n0YuWOq/qeQq92\n",
       "euwj+p6CevTg+o19T6FXy7Ypu93xJw+s73sKfSuzsmtJ2f80SZKkQRmXxEaSJLWtgKUoExtJkjQY\n",
       "JjaSJJXCRypIkiRNDhMbSZKK0VGPTY+5iYmNJEkaDBMbSZJKUcAjFUxsJEnSYJjYSJJUCvexkSRJ\n",
       "mhwWNpIkaTBcipIkqRQ2D0uSJE0OExtJkgpRVRVVB2lKF2PMxcRGkiQNhomNJEmFqFtsukhsWh9i\n",
       "TiY2kiRpMExsJEkqRdUcXYzTExMbSZI0GCY2kiQVwruiJEmSJoiJjSRJhajoKLHpscnGxEaSJA2G\n",
       "hY0kSRqMVpeiImIKeD+wK/AA8JrM/GabY0qSpE2zeXjrvQRYlpn7AH8MnNryeJIkqWBtFzbPBS4D\n",
       "yMzrgD1bHk+SJM1hJrHp4uhL24XN9sCaWecbmuUpSZKkRdf27d5rgBWzzqcyc2PLY0qSpE3xkQpb\n",
       "7VrgNwEiYm/gxpbHkyRJBWs7sfk4cHBEXNucH9PyeJIkaS5d9b/02GPTamGTmdPA77c5hiRJ0gwf\n",
       "qSBJUiHcx0aSJGmCWNhIkqTBcClKkqRClLAUZWEjSZI6FxF7Aadk5oER8VFgZfOjnYH/nZm/FxGn\n",
       "Uz/F4MfANPCSzFyz6SvWLGwkSSpEVXWTpiw0REScCBwFrAXIzJc17/8c8BngPzcf3R04JDN/OOrY\n",
       "9thIkqSu3QIcwb/fo/jPgDMy887mEUxPAc6KiGsiYqS98CxsJEkqSdXBsYDMvAhYP/u9iHg88OvA\n",
       "6uatRwBnAEcChwKvj4inL3RtCxtJkjQOfgc4v9ncF+An1OnN/Zm5FrgS2G2hi9hjI0lSIcb8rqiD\n",
       "gP826zyAv4uI3YElwL48lObMycRGkiT1ZXrW6wBunTnJzG8AHwL+mbqheHXz3rxMbCRJKsQ4JTaZ\n",
       "eRuwz6zzX9vEZ04DTtucsU1sJEnSYJjYSJJUiHFKbNpiYiNJkgbDwkaSJA2GS1GSJJVixA30FmWc\n",
       "npjYSJKkwTCxkSSpEDYPS5IkTRATG0mSStFRYoOJjSRJ0tYzsZEkqRBVVXWSpthjI0mStAhMbCRJ\n",
       "KkRFR4lNjxvZmNhIkqTBsLCRJEmDMVZLUX/75t/gcStX9T2NXrzivM/3PYVeXX7C8/qeQq+WLulx\n",
       "//ExsHHjdN9T6NWGwr//dsuW9D2FXixf2kO24CMVJEmSJsdYJTaSJKk9VUVHt3u3PsScTGwkSdJg\n",
       "mNhIklQIN+iTJEmaICY2kiQVwsRGkiRpgpjYSJJUCvexkSRJmhwmNpIkFcIeG0mSpAliYSNJkgbD\n",
       "pShJkgrhUpQkSdIEMbGRJKkYVUdpiomNJEnSVjOxkSSpEF312HQyxhxMbCRJ0mCY2EiSVAofqSBJ\n",
       "kjQ5TGwkSSqEPTaSJEkTxMRGkqRCVBUdJTbtDzEXExtJkjQYFjaSJGkwXIqSJKkQlbd7S5IkTQ4T\n",
       "G0mSCuHt3osoIvaKiM90NZ4kSSpPJ4lNRJwIHAWs7WI8SZL079ljs3huAY6g168qSZKGrpPCJjMv\n",
       "AtZ3MZYkSdq0ioqq6uDoMcfwrihJkjQY3hUlSVIpOroparqAHpsZ0x2PJ0mSCtJZYpOZtwH7dDWe\n",
       "JEkqj0tRkiQVYmqqoppqf51oeqpiY+ujbJrNw5IkaTBMbCRJKkRXT1QoYYM+SZKk1pnYSJJUiJkN\n",
       "9DoYqP0x5mBiI0mSBsPERpKkQoxTj01E7AWckpkHRsQzgU8CNzc/fn9mXhARrwWOpX4s0zsz89KF\n",
       "rmthI0mSOhURJwJHAWubt/YATsvM02Z95gnAG5ufbQdcExH/kJkPzndtCxtJkgoxRj02twBHAB9u\n",
       "zvcAdomIw6lTmzcBzwauzcx1wLqIuAXYFbhhvgvbYyNJkjqVmRdRLy/NuA54c2buD9wK/AmwArhn\n",
       "1md+DOyw0LUtbCRJKkb109SmzWMLNrL5eGZ+ceY18ExgDXVxM2MFcPdCF7KwkSRJfbssIp7VvP4N\n",
       "6uWm64HnRcTyiNgBeCrw1YUuZI+NJEnqy3Tz1+OA90XEOuB24NjMXBsRZwCfow5iTlqocRgsbCRJ\n",
       "KkZXt3uPMkZm3gbs07z+MrDvJj5zNnD25oztUpQkSRoMExtJkgrR1e3endxSPgcTG0mSNBgmNpIk\n",
       "FWKcemzaYmIjSZIGw8RGkqRC1IlNFz02rQ8xJxMbSZI0GCY2kiQVwh4bSZKkCWJhI0mSBsOlKEmS\n",
       "CuEGfZIkSRPExEaSpEKU0Dw8VoVNrFrBTjvt0Pc0enHlf9mv7yn06jEvOLXvKfTq2xe9qe8p9Gq7\n",
       "ZUv6nkKv7rjn/r6n0KtVj96u7yn0os/lmiEbq8JGkiS1qZseG7DHRpIkaauZ2EiSVIgSemxMbCRJ\n",
       "0mCY2EiSVAj3sZEkSZogJjaSJBXCHhtJkqQJYmEjSZIGw6UoSZIKYfOwJEnSBDGxkSSpEDYPS5Ik\n",
       "TRATG0mSCmGPjSRJ0gQxsZEkqRAmNpIkSRPExEaSpIL0ecdSF0xsJEnSYFjYSJKkwXApSpKkQtg8\n",
       "LEmSNEFMbCRJKoSPVJAkSZogJjaSJBWiTmy66LFpfYg5mdhIkqTBMLGRJKkQ9thIkiRNkNYSm4hY\n",
       "CpwDPAlYDrwzMz/Z1niSJGl+U1XFVAdxShdjzDl2i9c+Evh+Zu4HHAqc2eJYkiRJrfbYXABc2Lye\n",
       "Ata3OJYkSVpACT02rRU2mXkvQESsoC5y3tbWWJIkSdBy83BEPBG4EvhQZn60zbEkSZLabB5eCVwB\n",
       "vD4zP9PWOJIkaUQdPQSzz7WoNntsTgJ2AE6OiJOb9w7LzPtbHFOSJBWszR6bE4AT2rq+JEnaPFPA\n",
       "VAdhSp+b5LlBnyRJGgwfqSBJUiGqjnpsOunjmYOJjSRJGgwTG0mSClHCBn0mNpIkaTBMbCRJKkTV\n",
       "/OpinL6Y2EiSpMEwsZEkqRBTVUf72IwwRkTsBZySmQdGxDOAM4ANwAPA0Zn5vYg4HXgu8GNgGnhJ\n",
       "Zq6Z77oWNpIkqVMRcSJwFLC2eeu9wBsy88aIOBZ4C/CHwO7AIZn5w1Gv7VKUJEnq2i3AEfDTZpyX\n",
       "ZeaNzeulwH0RUQFPAc6KiGsi4phRLmxhI0lSKZoN+to+FrrfOzMvAtbPOr8DICL2AY4H3gM8knp5\n",
       "6kjgUOD1EfH0hb6ihY0kSepdRLwU+ADwm5l5F/AT4IzMvD8z1wJXArstdB17bCRJKsS4btAXEUcB\n",
       "xwIHZObdM28DfxcRuwNLgH2B1Qtdy8JGkiT1ZToipoDTgf8DXBQRAJ/NzHdExIeAfwbWAasz8xsL\n",
       "XdDCRpKkQkxVFVMdRDajjJGZtwH7NKc/P8dnTgNO26yxN+fDkiRJ48zERpKkQoxrj81iMrGRJEmD\n",
       "YWIjSVIhKpp9ZjoYpy8mNpIkaTAsbCRJ0mC4FCVJUiFsHpYkSZogJjaSJBWiqkbbPG8xxumLiY0k\n",
       "SRoMExtJkgpRNUcX4/TFxEaSJA2Gic2Y6GLDpHH2g0/9Yd9T6NVjDzul7yn06u7L39r3FHq1codt\n",
       "+56CClFVHW3Q1+OfaSY2kiRpMExsJEkqxFRVH12M0xcTG0mSNBhzJjYRce48v286M1/VwnwkSVJL\n",
       "SuixmW8p6ipgmofu2ppu/lrNei1JkjQ25ixsMnP1zOuI2Bl4GnA58MTMvLX9qUmSJG2eBXtsIuJl\n",
       "wCXA6cDPA9dGxMvbnpgkSVpcMw/B7OLoyyjNw28Bngusycw7gN2BsjedkCRJY2mUwmZDZq6ZOcnM\n",
       "24EN7U1JkiS1YaZ5uIujL6PsY/O1iHgjsCwingG8HvhSu9OSJEnafKMkNscDOwH3AecAa6iLG0mS\n",
       "NEEqHtqkr82jz4cELZjYZObaiPivwPnAeuDmzFzf+swkSZI204KFTUQ8D/gwcBd1EbYiIn4vMz/f\n",
       "9uQkSdLiKX2DvhnvBV6cmTcCRMSewPuBZ7c5MUmSpM010rOiZoqa5vUNwNLWZiRJklpRdXj0Zb5n\n",
       "Re1OPbevRcTpwNnUt3kfCfxLN9OTJEka3XxLUafx0DOhfhE4o3nts6IkSdJYmu9ZUQd0OA9JktSy\n",
       "qapiqoPG3i7GmMuod0X9EfBI6p6cJcAvZuaT252aJEnS5hmlefhs4GLqIuhM4GbgPW1OSpIkLT4f\n",
       "glm7LzPPAa4C7gZeC/xOq7OSJEnaAqPsY3NfRDwGSGBv4DPA41qdlSRJWnQlbNA3SmJzGvAx4BLg\n",
       "FcDXgC+0OSlJkqQtsWBhk5kXAAdn5o+B3an3sTmq7YlJkqRF1lV/TY89NvNt0Hfuw85nn04Dr2pp\n",
       "TpIkSVtkvh6bq6gLmJm66+GvJUnSBCl6H5vMXN3hPCRJkrbaKHdFSZKkAehqj5k+97FptbCJiCXA\n",
       "WcAu1MtXx2Xm19ocU5IklWvBu6Ii4q2beO8vRrz+C4GNmbkv8HbgzzdvepIkSaOb766oU4CVwIsj\n",
       "YpeH/Z69gZMWunhmfiIiPtWcPpl652JJktSDim42z+txJWrepaiLgF8FDgI+Sz3PaWA98GejDpCZ\n",
       "GyJiNfBb+CgGSZLUojmXojLz+ubOqN2BHzWvLwW2BW7ZnEEy85XUfTZnRcR2WzpZSZK05aY6PPoy\n",
       "ytjvBn571vmvA389ysUj4uWzenTuAzY2hyRJ0qIb5a6oZ2XmrwFk5g+AIyPiKyNe/0JgdURcBSwF\n",
       "TsjMB7ZsqpIkaWuU8BDMUQqbKiJWZeZ3ASJiJbBhlItn5n3AS7difpIkSSMbpbD5c+ALEXFtc74X\n",
       "cEJ7U5IkSW2oKpga+AZ9ozzd+yPAHsBHgPOol6b+vu2JSZIkba5RNuhbDrwSOBy4GnhtRCxreV6S\n",
       "JGmRTVXdHb19xxE+8z7gUdSpzXrgKcAH25yUJEnSlhilsNkjM98KPJiZa4Gjqfe2kSRJGiujNA9v\n",
       "fNjS02NxLxpJkiZOCbd7j5LYnA78I/CEiDgd+Ffgva3OSpIkaQuMkth8mrqYOZC6EHphZt7Y6qwk\n",
       "SdKi66qxt8/m4VEKm89l5q8AX2t7MpIkSVtjlMLmSxFxNHAd9fOeAMjM/9varCRJ0qKrqm42zxtl\n",
       "jIjYCzglMw+MiF8GVlP38H4VOD4zpyPitcCx1HdlvzMzL13ouqP02OwNvAO4DLhq1iFJkrTZIuJE\n",
       "4CxgefPWacBJmbkfUAGHR8QTgDcC+wDPB941yj56oyQ2b8jMT23RzCVJ0tioqoqp8bgr6hbgCODD\n",
       "zfnumXl18/rTwCHUz6W8NjPXAesi4hZgV+CG+S48SmLzlyN8RpIkaSSZeRH18tKM2ZXQj4EdgO2B\n",
       "ezbx/rxGSWy+GRHnUPfY3N+8N52ZHxrh90qSpDExxWiJxmKMs5lm74+3PfAjYA2wYtb7K4C7F2Ps\n",
       "u6grqb2BA5rjwNHmKUmStKAvRsT+zevDqJ9NeT3wvIhYHhE7AE+lbiye14KJTWa+smnWiebzX23W\n",
       "uyRJ0gSp6OiuqNE/Ot389Q+Bs5p64+vAhc1dUWcAn6MOYk7KzAcXuuCChU1E7AlcCPywmevKiDgi\n",
       "M/9l9HlLkiQ9JDNvo77jicy8mXpF6OGfORs4e3OuO0qPzRnASzPzOoCI2Lt579mbM5AkSVLbRumx\n",
       "eeRMUQPQJDXbtjclSZLUhqnmdu8ujt6+4wifuTsiXjJzEhG/Rd1QLEmSNFZGWYo6FvjbiPggdY/N\n",
       "N4GjWp2VJEladOP0SIW2jHJX1E0R8SLgXmAJ8PimyUeSJGmsLLgUFRF/AFyWmWuBRwOfjIjXtT4z\n",
       "SZK0qKoKpjo4+kxsRumxeR2wL/z01qzdqR9KJUmSNFZG6bHZBpi9Ic6D/OzWx5IkaQJ0dcdSn3dF\n",
       "jVLYXAxcGRH/k7p5+AjgklZnJUmStAVGaR5+S0T8LrAfsA44PTMvbn1mkiRpUXlXVCMzLwAuaHku\n",
       "RVu/oezVvQ0bpxf+0IDdfflb+55Crx79Wx/oewq9+sHfH9f3FKTBGKmwkSRJk2/mrqUuxunLKHdF\n",
       "SZIkTQQLG0mSNBguRUmSVIiq+dXFOH0xsZEkSYNhYiNJUiGqjpqHx/2RCpIkSRPBxEaSpEJM0dHt\n",
       "3u0PMZZjS5IkLSoTG0mSClFVFVUHDTBdjDEXExtJkjQYJjaSJBXCRypIkiRNEAsbSZI0GC5FSZJU\n",
       "iKrqZvM8N+iTJElaBCY2kiQVon6kQhe3e7c+xJxMbCRJ0mCY2EiSVAhv95YkSZogJjaSJBXCu6Ik\n",
       "SZImiImNJEmFmKJiivbjlC7GmHtsSZKkgTCxkSSpEPbYSJIkTRALG0mSNBitL0VFxOOBfwUOysyb\n",
       "2h5PkiRtWkU3m+f1uBLVbmITEUuBvwHubXMcSZIkaH8p6t3AB4DbWx5HkiQtYKqqOjt6+45tXTgi\n",
       "Xgl8PzOvaN7qM5mSJEkFaDOxOQY4OCI+AzwDOC8iVrY4niRJmsfM7d5dHH1prXk4M/efed0UN6/L\n",
       "zDvbGk+SJMkN+iRJKkRX/S999th0Uthk5oFdjCNJkspmYiNJUiF8pIIkSdIEsbCRJEmD4VKUJEmF\n",
       "qOgm0RjsIxUkSZK6ZGIjSVIhqqqi6qCzt4sx5mJiI0mSBsPERpKkQlR00/9ij40kSdIiMLGRJKkQ\n",
       "JTxSwcRGkiQNhomNJEmFGJcem4h4BfDK5nQ7YDfgOcClwE3N+x/IzI9t7tgWNpIkqVOZeR5wHkBE\n",
       "nAmcDewBnJqZp23NtV2KkiSpEDMPweziGEVE7Ak8LTPPBvYEXhARV0XE2RHxqC35jhY2kiSpLycB\n",
       "f9q8vg54c2buD9wK/MmWXNDCRpIkdS4ifg7YJTOvat76eGZ+sXl9MfDMLbmuhY0kScWofvpYhTaP\n",
       "EVuU9wP+adb5ZRHxrOb1QcANW/INbR6WJEl92AX45qzz44D3RcQ64Hbg2C25qIWNJEmFmKKbpZpR\n",
       "xsjMv3rY+ZeBfbsYW5IkaSKY2EiSVIiHemDaH6cvJjaSJGkwTGwkSSrEuDxSoU0mNpIkaTBMbCRJ\n",
       "KkT9uIMuemxaH2JOJjaSJGkwLGwkSdJguBQ1Jqb6zO3GwN33ret7Cr3aofS//x///b6n0Ksdjzm/\n",
       "7yn06vZzj+x7CsUYpw36hji2JEnSojKxkSSpFB1t0Ndn97CJjSRJGgwTG0mSCuEGfZIkSRPExEaS\n",
       "pELUG/R1M05fTGwkSdJgmNhIklSIKSqmOuiA6WKMuceWJEkaCBMbSZIKYY+NJEnSBLGwkSRJg+FS\n",
       "lCRJhaiaX12M0xcTG0mSNBgmNpIkFcLmYUmSpAliYiNJUiGqjjbos8dGkiRpEZjYSJJUCHtsJEmS\n",
       "JoiJjSRJhajoKLFpf4g5mdhIkqTBsLCRJEmD4VKUJEmF8JEKkiRJE8TERpKkQkxV9dHFOH0xsZEk\n",
       "SYNhYiNJUiFK6LFptbCJiC8A9zSnt2bmq9scT5Ikla21wiYitgXIzAPbGkOSJG2Gjh6p0OcOfW0m\n",
       "NrsBj4iIy5txTsrM61ocT5IkFa7N5uF7gXdn5vOB44DzI8JmZUmSelJ1+KsvbRYaNwHnA2TmzcBd\n",
       "wI4tjidJkgrX5lLUMcCuwPERsQrYHri9xfEkSdI8StjHps3C5oPAuRFxdXN+TGZubHE8SZJUuNYK\n",
       "m8xcD7y8retLkiQ9nBv0SZJUiIpuNs/rcSXKRypIkqThMLGRJKkQVUcb9HWyCeAcTGwkSdJgmNhI\n",
       "klSIim76X+yxkSRJWgQmNpIkFaKqKqY6aICpemyyMbGRJEmDYWIjSVIh7LGRJEmaICY2kiSVooDI\n",
       "xsRGkiQNhoWNJEkaDJeiJEkqRNX86mKchUTEF4B7mtNbgXcBq4GNwFeB4zNzenPHtrCRJEmdioht\n",
       "ATLzwFnvXQKclJlXR8QHgMOBizf32hY2kiQVYowegrkb8IiIuJy6FnkbsHtmXt38/NPAIWxBYWOP\n",
       "jSRJ6tq9wLsz8/nAccD5D/v5WmCHLbmwhY0kSYWoOjwWcBNNMZOZNwN3AStn/XwF8KMt+Y4WNpIk\n",
       "qWvHAKcCRMQq6kLmiojYv/n5YcDVc/zeedljI0lSSfp83sFDPgicGxEzxcsx1KnNWRGxDPg6cOGW\n",
       "XNjCRpIkdSoz1wMv38SPDtjaa1vYSJJUiHHax6Yt9thIkqTBsLCRJEmD4VKUJEmFGKMN+lpjYiNJ\n",
       "kgbDxEaSpEKMuHneoozTl7EqbO5/cAM/eWB939PoxXbLlvQ9hV49bvvlfU9B6s3t5x7Z9xR69ehn\n",
       "vaHvKfRiycb72KnvSQzQWBU2kiSpRQVENvbYSJKkwTCxkSSpGN1s0NdnZGNiI0mSBsPERpKkQriP\n",
       "jSRJ0gQxsZEkqRAF3BRlYiNJkobDwkaSJA2GS1GSJJWigLUoExtJkjQYJjaSJBWi6miDvm42Adw0\n",
       "ExtJkjQYJjaSJBXCDfokSZImiImNJEmFKOCmKBMbSZI0HCY2kiSVooDIxsRGkiQNhoWNJEkaDJei\n",
       "JEkqhBv0SZIkTRATG0mSCuEGfZIkSRPExEaSpIL0uXleF0xsJEnSYJjYSJJUkoFHNiY2kiRpMFpN\n",
       "bCLircCLgKXAmZl5XpvjSZKkubmPzVaIiAOA52TmPsABwC+1NZYkSRK0m9gcAnwlIi4Gtgf+qMWx\n",
       "JEnSAkrYx6bNwuZxwBOBF1KnNZcAv9LieJIkqXBtNg//ALgiM9dn5k3A/RHx2BbHkyRJhWuzsLkG\n",
       "OBQgIlYBjwTuanE8SZI0j6rDoy+tFTaZeSnwxYi4nnoZ6vWZOd3WeJIkSa3e7p2Zb2nz+pIkaTN0\n",
       "Faf4EExJkqSt5yMVJEkqRB3YdLFBX39MbCRJ0mCY2EiSVIgSNugzsZEkSYNhYiNJUiEKuCnKxEaS\n",
       "JA2HhY0kSRoMl6IkSSpFAWtRJjaSJGkwTGwkSSpE1fzqYpy+mNhIkqTBMLGRJKkUHW3QZ4+NJEnS\n",
       "IjCxkSSpEONyU1RELAXOAZ4ELAfeCXwb+BRwU/OxD2TmxzZ3bAsbSZLUtSOB72fmyyPi0cCXgXcA\n",
       "p2bmaVtzYQsbSZJKMS6RDVwAXNi8ngLWAXsAERGHAzcDb8rMtZs7tD02kiSpU5l5b2aujYgV1EXO\n",
       "24DrgTdn5v7ArcCfbMm1LWwkSSpE1eGvhUTEE4ErgQ9l5keBj2fmF5sfXww8c0u+o4WNJEnqVESs\n",
       "BK4ATszM1c3bl0XEs5rXBwE3bMm17bGRJEldOwnYATg5Ik5u3nsT8J6IWAfcDhy7JRe2sJEkqRBV\n",
       "Rxv0LTRGZp4AnLCJH+27tWO7FCVJkgbDxEaSpEKMz93e7TGxkSRJg2FiI0lSISo66rFpf4g5jUth\n",
       "swTge3fe0fc8erN8adnhWdXJ42YljaMlG+/rewq9WLLx/p++7HMeQzMuhc2OAMe9+ui+5yFJ6thO\n",
       "fU+gfzsC3+xmqOF32YxLYfN54HnU961v6HkukiR1YQl1UfP5vicyJGNR2GTmA8A1fc9DkqSOdZTU\n",
       "1MZlH5s2ld3YIUmSBmUsEhtJktS+4XfYmNhIkqQBsbCRJEmD4VKUJEml6Kh5uM+1qOILm4iYAt4P\n",
       "7Ao8ALwmMzvtUh8HEbEXcEpmHtj3XLoSEUuBc4AnAcuBd2bmJ/udVXciYglwFrALMA0cl5lf63dW\n",
       "3YuIxwNer5ITAAAH4ElEQVT/ChyUmTf1PZ8uRcQXgHua01sz89V9zqdLEfFW4EXAUuDMzDyv5ylp\n",
       "kbgUBS8BlmXmPsAfA6f2PJ/ORcSJ1H/ALe97Lh07Evh+Zu4HHAqc2fN8uvZCYGNm7gu8HfjznufT\n",
       "uaa4/Rvg3r7n0rWI2BYgMw9sjpKKmgOA5zT/3j8A+KVeJ9ShqsNffbGwgecClwFk5nXAnv1Opxe3\n",
       "AEfQbyN7Hy4ATm5eTwHre5xL5zLzE8DrmtMnA3f3N5vevBv4APXmoKXZDXhERFweEf/UpLalOAT4\n",
       "SkRcDHwSuKTn+WgRWdjA9sCaWecbmuWpYmTmRRT2hzpAZt6bmWsjYgV1kfO2vufUtczcEBGrgTOA\n",
       "j/Q8nU5FxCupE7srmrdKK+zvBd6dmc8HjgPOL+jffY8D9gB+h+a79zudDlUdHj0p5f/E81kDrJh1\n",
       "PpWZG/uajLoVEU8ErgQ+lJkf7Xs+fcjMV1L32ZwVEdv1PJ0uHQMcHBGfAZ4BnBcRK3ueU5duovkD\n",
       "PTNvBu6ieW5fAX4AXJGZ65u+qvsj4rF9T0qLw8IGrgV+EyAi9gZu7Hc66krzh9gVwImZubrn6XQu\n",
       "Il7eNFAC3AdsbI4iZOb+mXlA0zD/JeDozLyz73l16BiansKIWEWdXpeyJHcNdV/dzHd/JHVhN3gF\n",
       "BDbeFQV8nPq/2q5tzo/pczI9m+57Ah07CdgBODkiZnptDsvM+3ucU5cuBFZHxFXUd4ac0Dy3TWX4\n",
       "IHBuRFzdnB9TSlqdmZdGxH4RcT31f+C/PjNL+/ffYFXT0/69lCRpyCLiycC3PnbJ5ey4aqfWx7v9\n",
       "u9/hP774+QA7Z+ZtrQ84i0tRkiRpMCxsJEnSYNhjI0lSIbraPM8N+iRJkhaBiY0kSaXo6l5sN+iT\n",
       "JEnaehY20gBExJkR8YqI2DEiLl3gs5/ZzGvvuanfExGfjYj95/l9T46Ir2zmWPNeU9LWcYM+SZNi\n",
       "GiAzbwdesMBnF6twmGbxN3Vs45qSCmJhI/UgIg4A3t6c/gJwPfAaYBX10+a/T/2Yg0OBv6IuRpYA\n",
       "qzPzvRFRUT+Z+kXAncCDwOebTbg+m5lPjognAedSP/DvJ831X9uM/8+Z+ZyIOBR4B/XOw98CXpuZ\n",
       "P4yIg4HTgAeAry3wXZYAfw08DVgJJPXT4gEeFREXAf+B+tlEr87MNRHxrOb6j6B+bs/rut7ESypR\n",
       "VdVHF+P0xaUoqT97A68DngpsCxzfvL8LcGRmHgIcC0xn5h7AXsDhEbEvdeGwJ/CrwOHAL8+67kzi\n",
       "8X7ggsx8OvCnwNsy8w8AmqLmccC7gEMyc3fq52b994hYBpwHvDQz96R+UOxcKmAf4P7M3KeZx3Y0\n",
       "z1+jLtr+IjN3oy6c3h4RS4Gzgf/UfK/TgLNG/59NkuZmYiP15x8z85sAEfFh6iLmIuB7mfl/m8/8\n",
       "BrBbRPx6c/5I4OnUBc2FmbkBuDsiLt7E9fcDXgqQmZ8GPv2wn+8F/CLw2YiAOhG6q7n+7Zn59eZz\n",
       "HwTeM8d3mM7Mz0XEDyPieOBXgKc085wGvpKZNzSf/TCwmrpo+iXgk824ACvmuL6kRVTCPjYWNlJ/\n",
       "1s96vWTW+X2z3p8C/igzLwZoUpYfA3/JzyauGzZx/XXM6uGLiKdm5jceNuY1mXl48/NtqQuMJ/Kz\n",
       "vX+buvaMKiJeTL2c9V7gHODnZ/3+2d9xqjlfAtyamc9sxp0CnjDPGJI0MpeipP4cGBFPaP5gPxr4\n",
       "X/z7mwmuBI6NiG0iYgXwOeDZwD8AL4uIZRGxPZtuGL4aeBlA0zPzP5r3NzR9MdcBz4mIpzTvv526\n",
       "YLoReHxEPLN5//cW+B4HAR/LzPOo+332oy5eKuq06WnN517VzPvfgMc0S2oz75+/wBiSFkP1UJ9N\n",
       "m0eft0WZ2Ej9+Q71H+irqPtbzgaexM/eFfTX1Es7X6T+5/WDmXk11LdhA1+lbjT+t+bzs+8qegNw\n",
       "dkS8HriXunkY4BPAl6h7dF4FfKwpdP4fcFRmro+IlwLnRsQG4PPMfafSNHV/zEci4gjgjub6O1MX\n",
       "ZQn8RUTsDHwZeGtmPhgRvwuc3qRE9wCv2Jz/4SRpLtX0tHdWSl1r7op6S2Ye1vdcJA1fc8fkty66\n",
       "9B9YtWqn1sf77ne/wxEvOBhg567veHQpSuqH+7VIUgtcipJ6kJlXAVf1PQ9JGhoLG0mSClHR0QZ9\n",
       "7Q8xJ5eiJEnSYJjYSJJUiBI26DOxkSRJg2FiI0lSIXwIpiRJ0gQxsZEkqRBdPe3Au6IkSZIWgYWN\n",
       "JEkaDJeiJEkqRQFrUSY2kiRpMExsJEkqRB3YdLFBX39MbCRJ0mCY2EiSVAg36JMkSZogJjaSJBWi\n",
       "gJuiTGwkSdJwmNhIklSKAiIbExtJkjQYJjaSJBWj6mQfmz4jGwsbSZLUqYiYAt4P7Ao8ALwmM7+5\n",
       "GNd2KUqSJHXtJcCyzNwH+GPg1MW6sImNJEmF+N6dd3Syed737rxjoY88F7gMIDOvi4g9F2tsCxtJ\n",
       "kgpxzNFH9j2FGdsDa2adb4iIqczcuLUXtrCRJGn4vg3s3NO4m7IGWDHrfFGKGrCwkSRp8DJzPXBb\n",
       "3/OY5VrgRcAFEbE3cONiXdjCRpIkde3jwMERcW1zfsxiXbianp5erGtJkiT1ytu9JUnSYFjYSJKk\n",
       "wbCwkSRJg2FhI0mSBsPCRpIkDYaFjSRJGgwLG0mSNBj/H3aQR6gpDETPAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x100734610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
    "plt.xlabel(\"predicted label\")\n",
    "plt.ylabel(\"correct label\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[179,  32,   0,   0,   6,   0,  10],\n",
       "       [ 49, 141,   6,   1,   9,   3,   1],\n",
       "       [  0,   1, 195,  12,   2,  27,   0],\n",
       "       [  0,   0,   3, 198,   0,   3,   0],\n",
       "       [  0,   4,   7,   0, 189,   3,   0],\n",
       "       [  0,   2,  22,   6,   0, 177,   0],\n",
       "       [ 10,   1,   0,   0,   0,   0, 213]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So out of the box, the random forrest gives us fairly good results with default settings - an overall accuracy of 0.83.  Lets see if we can take advantage of some of the nice SVM properties with different kernels.  We have both continuous and binary data - if we can use a polynomial kernel with the binary data (computing logical conjunctions) and an rbf kernel with the continuous data, all optimized with a GP, maybe we can improve our results evern further\n",
    "\n",
    "\n",
    "Polynomial Kernel\n",
    "\n",
    "$$K(x, y) = (x \\cdot y^{T} + c)^d$$\n",
    "\n",
    "Therefore we'll need to choose values of c and values of $d \\geq 1$\n",
    "\n",
    "RBF Kernel\n",
    "\n",
    "$$K(x, y) = exp(\\frac{||x - y ||^2}{2\\sigma^2}) $$\n",
    "\n",
    "Therefore we'll need to choose a value of sigma for each real valued dimension -  though at first we'll use one value.\n",
    "\n",
    "In order to combine the kernels we will precompute the gram matrix for python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_gram(X, gamma=0.1, d=3):\n",
    "    gram_real = np.zeros((len(X), len(X)), dtype=np.float64)\n",
    "    gram_binary = np.zeros((len(X), len(X)), dtype=np.int64)\n",
    "    \n",
    "    # Compute Kernel for real valued features\n",
    "    gram_real = (np.sum(X[:,0:10]**2, 1).reshape(-1, 1) + np.sum(X[:,0:10]**2, 1)\n",
    "                 -2 * np.dot(X[:,0:10], X[:,0:10].T))\n",
    "    gram_real = np.exp(gamma * gram_real)\n",
    "    \n",
    "    # Compute Kernel for binary features\n",
    "    gram_binary = (np.dot(X[:,10:], X[:,10:].T))**d\n",
    "    return gram_real * gram_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we should normalize the real features for numerical stability\n",
    "X_train_norm = X_train.copy()\n",
    "X_train_norm = X_train_norm.astype(float)\n",
    "X_train_norm[:,0:10] = (X_train_norm[:, 0:10] - np.mean(X_train[:, 0:10], axis=0)) / np.std(X_train[:,0:10], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gram_matrix = compute_gram(X_train_norm, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   4.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   4.30892139e+03,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   4.00000000e+00, ...,\n",
       "          8.86156321e+01,   0.00000000e+00,   3.80965787e+01],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   0.00000000e+00,   8.86156321e+01, ...,\n",
       "          4.00000000e+00,   0.00000000e+00,   1.06657339e+01],\n",
       "       [  0.00000000e+00,   4.30892139e+03,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   4.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   3.80965787e+01, ...,\n",
       "          1.06657339e+01,   0.00000000e+00,   4.00000000e+00]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"precomputed\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='precomputed', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(gram_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15174897119341563"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(gram_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current score: 0.524323927102, best score: 0\n",
      "current score: 0.155349794239, best score: 0.524323927102\n",
      "current score: 0.459729570841, best score: 0.524323927102\n",
      "current score: 0.4699441505, best score: 0.524323927102\n",
      "current score: 0.580393885949, best score: 0.524323927102\n",
      "current score: 0.143812463257, best score: 0.580393885949\n",
      "current score: 0.595238095238, best score: 0.580393885949\n",
      "current score: 0.41879776602, best score: 0.595238095238\n",
      "current score: 0.472075249853, best score: 0.595238095238\n",
      "current score: 0.597810111699, best score: 0.595238095238\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_params = [0, 0, 0]\n",
    "for i in range(10):\n",
    "    c = np.random.randint(-20, 20)\n",
    "    g = np.random.randint(-20, 0)\n",
    "    d = np.random.randint(1, 5)\n",
    "\n",
    "    gram_matrix = compute_gram(X_train_norm, gamma=2**g, d=d)\n",
    "    clf = SVC(kernel=\"precomputed\", C=2**c)\n",
    "    clf.fit(gram_matrix, y_train)\n",
    "    score = clf.score(gram_matrix, y_train)\n",
    "    print \"current score: \" + str(score) + \", best score: \" + str(best_score)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = [c, g, d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, -19, 3]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well I had some slight improvement - but really its still pretty shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_norm = X_test.copy()\n",
    "X_test_norm[:, 0:10] = (X_test_norm[:, 0:10] - np.mean(X_train[:, 0:10], axis=0)) / np.std(X_train[:,0:10], 0)\n",
    "X_train_norm = X_train.copy()\n",
    "X_train_norm = X_train_norm.astype(float)\n",
    "X_train_norm[:,0:10] = (X_train_norm[:, 0:10] - np.mean(X_train[:, 0:10], axis=0)) / np.std(X_train[:,0:10], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61904761904761907"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_norm, y_train)\n",
    "clf.score(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about total overkill?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "import keras.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 7044 12136  7130 ...,  4171  3360  1039] TEST: [12841 13526  1512 ...,  4215 13122 12759]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "X = data.values[:, 0:-1]\n",
    "y = data.values[:, -1]\n",
    "# convert 0 and 1 to -1 and 1\n",
    "X[:,10:] *= 2\n",
    "X[:,10:] -= 1\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(y, n_iter=1, test_size=0.15, random_state=0)\n",
    "\n",
    "\n",
    "for train_index, test_index in sss:\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "X_train[:,0:10] = (X_train[:,0:10] - np.mean(X_train[:,0:10], 0)) / np.std(X_train[:,0:10], 0)\n",
    "X_test[:,0:10] = (X_test[:,0:10] - np.mean(X_train[:,0:10], 0)) / np.std(X_train[:,0:10], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 0\n",
      "12852/12852 [==============================] - 1s - loss: 29.5417     \n",
      "Epoch 1\n",
      "12852/12852 [==============================] - 2s - loss: 29.5584     \n",
      "Epoch 2\n",
      "12852/12852 [==============================] - 2s - loss: 29.5690     \n",
      "Epoch 3\n",
      "12852/12852 [==============================] - 2s - loss: 29.5957     \n",
      "Epoch 4\n",
      "12852/12852 [==============================] - 2s - loss: 29.5903     \n",
      "Epoch 5\n",
      "12852/12852 [==============================] - 2s - loss: 29.6604     \n",
      "Epoch 6\n",
      "12852/12852 [==============================] - 2s - loss: 29.6092     \n",
      "Epoch 7\n",
      "12852/12852 [==============================] - 2s - loss: 29.5742     \n",
      "Epoch 8\n",
      "12852/12852 [==============================] - 3s - loss: 29.6821     \n",
      "Epoch 9\n",
      "12852/12852 [==============================] - 3s - loss: 29.6820     \n",
      "Epoch 10\n",
      "12852/12852 [==============================] - 3s - loss: 29.6068     \n",
      "Epoch 11\n",
      "12852/12852 [==============================] - 3s - loss: 29.6418     \n",
      "Epoch 12\n",
      "12852/12852 [==============================] - 3s - loss: 29.6147     \n",
      "Epoch 13\n",
      "12852/12852 [==============================] - 2s - loss: 29.5851     \n",
      "Epoch 14\n",
      "12852/12852 [==============================] - 2s - loss: 29.6309     \n",
      "Epoch 15\n",
      "12852/12852 [==============================] - 2s - loss: 29.5767     \n",
      "Epoch 16\n",
      "12852/12852 [==============================] - 2s - loss: 29.5907     \n",
      "Epoch 17\n",
      "12852/12852 [==============================] - 2s - loss: 29.6174     \n",
      "Epoch 18\n",
      "12852/12852 [==============================] - 2s - loss: 29.5878     \n",
      "Epoch 19\n",
      "12852/12852 [==============================] - 2s - loss: 29.5928     \n",
      "Epoch 20\n",
      "12852/12852 [==============================] - 2s - loss: 29.6174     \n",
      "Epoch 21\n",
      "12852/12852 [==============================] - 2s - loss: 29.5231     \n",
      "Epoch 22\n",
      "12852/12852 [==============================] - 2s - loss: 29.5094     \n",
      "Epoch 23\n",
      "12852/12852 [==============================] - 2s - loss: 29.5957     \n",
      "Epoch 24\n",
      "12852/12852 [==============================] - 2s - loss: 29.5902     \n",
      "Epoch 25\n",
      "12852/12852 [==============================] - 2s - loss: 29.6712     \n",
      "Epoch 26\n",
      "12852/12852 [==============================] - 2s - loss: 29.5288     \n",
      "Epoch 27\n",
      "12852/12852 [==============================] - 2s - loss: 29.6628     \n",
      "Epoch 28\n",
      "12852/12852 [==============================] - 2s - loss: 29.5422     \n",
      "Epoch 29\n",
      "12852/12852 [==============================] - 2s - loss: 29.6389     \n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train).astype(np.int32)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "nb_classes = y_train.shape[1]\n",
    "dims = X_train.shape[1]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(dims, 128, init='uniform'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, 128, init='uniform'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, nb_classes, init='uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "print(\"Training model...\")\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=30, batch_size=16, validation_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268/2268 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test - 1 != y_pred) / (len(y_test) * 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I maxedout at 0.85 error rate, very simil"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
